{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6164bc61-0d03-47b1-8df6-72077ac3367a",
   "metadata": {},
   "source": [
    "# FXの将来のリターン動向の予測モデル\n",
    "\n",
    "目的：過去18時間の **\"usdjpy\",\"cadjpy\"** を使って、将来**1時間後**のリターン動向を予測する   \n",
    "モデル：GCN   \n",
    "開発環境: python 3.11.5/ JupyterLab 3.6.3/Jupyter Notebook Version: 6.5.4/System: Linux #14~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f29210-8a01-473c-8d80-36bb27d4eb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.pool import global_mean_pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tslearn.metrics import dtw\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7077d-2938-4c1f-86d6-66197473c5aa",
   "metadata": {},
   "source": [
    "Pandas version: 2.0.3   \n",
    "Numpy version: 1.24.3   \n",
    "sklearn: 1.3.0   \n",
    "sklearn: 0.6.3   \n",
    "torch: 2.1.1   \n",
    "torch_geometric: 2.4.0   \n",
    "tqdm: 4.65.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7e703c-3832-499a-a82a-1670710f908b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times</th>\n",
       "      <th>Final Price</th>\n",
       "      <th>Final Price Normalized</th>\n",
       "      <th>1h_Return</th>\n",
       "      <th>Label</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-17 18:10:00</td>\n",
       "      <td>103.839</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-17 18:11:00</td>\n",
       "      <td>103.835</td>\n",
       "      <td>0.051867</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17 18:12:00</td>\n",
       "      <td>103.837</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-17 18:13:00</td>\n",
       "      <td>103.845</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-17 18:14:00</td>\n",
       "      <td>103.833</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Times  Final Price  Final Price Normalized  1h_Return  Label  \\\n",
       "0  2021-01-17 18:10:00      103.839                0.051946   0.000048      1   \n",
       "1  2021-01-17 18:11:00      103.835                0.051867  -0.000116      0   \n",
       "2  2021-01-17 18:12:00      103.837                0.051906  -0.000135      0   \n",
       "3  2021-01-17 18:13:00      103.845                0.052064   0.000010      1   \n",
       "4  2021-01-17 18:14:00      103.833                0.051827  -0.000106      0   \n",
       "\n",
       "   Currency  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times</th>\n",
       "      <th>Final Price</th>\n",
       "      <th>Final Price Normalized</th>\n",
       "      <th>1h_Return</th>\n",
       "      <th>Label</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-17 18:10:00</td>\n",
       "      <td>81.553</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-17 18:11:00</td>\n",
       "      <td>81.544</td>\n",
       "      <td>0.205841</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17 18:12:00</td>\n",
       "      <td>81.548</td>\n",
       "      <td>0.205949</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-17 18:13:00</td>\n",
       "      <td>81.554</td>\n",
       "      <td>0.206110</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-17 18:14:00</td>\n",
       "      <td>81.555</td>\n",
       "      <td>0.206136</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Times  Final Price  Final Price Normalized  1h_Return  Label  \\\n",
       "0  2021-01-17 18:10:00       81.553                0.206083   0.000368      1   \n",
       "1  2021-01-17 18:11:00       81.544                0.205841   0.000270      1   \n",
       "2  2021-01-17 18:12:00       81.548                0.205949   0.000307      1   \n",
       "3  2021-01-17 18:13:00       81.554                0.206110   0.000405      1   \n",
       "4  2021-01-17 18:14:00       81.555                0.206136   0.000442      1   \n",
       "\n",
       "   Currency  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "'''\n",
    "9 currency pairs from 2018-01-01 18:10:00 to 2023-11-17 16:10:00\n",
    "'''\n",
    "\n",
    "def load_dataset(filename, start_date, end_date):\n",
    "    \n",
    "    df = pd.read_csv(f'processed_data/{filename}.csv',sep = ',')\n",
    "    df.set_index('Times', inplace=True)\n",
    "    \n",
    "    df = df.loc[start_date:end_date]\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "start_date = '2021-01-17 18:10:00'\n",
    "end_date = '2023-11-17 16:10:00'\n",
    "\n",
    "variable_names = [\"usdjpy\",\"cadjpy\"]\n",
    "for name in variable_names:\n",
    "    exec(f\"{name} = load_dataset(str.upper('{name}'), start_date, end_date)\")\n",
    "    exec(f\"display({name}.head())\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594c34e0-a2ab-4c17-85f7-4af0b2283022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times</th>\n",
       "      <th>Final Price</th>\n",
       "      <th>Final Price Normalized</th>\n",
       "      <th>1h_Return</th>\n",
       "      <th>Label</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Times</th>\n",
       "      <th>Final Price</th>\n",
       "      <th>Final Price Normalized</th>\n",
       "      <th>1h_Return</th>\n",
       "      <th>Label</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-17 18:10:00</td>\n",
       "      <td>103.839</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-17 18:10:00</td>\n",
       "      <td>81.553</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-17 18:11:00</td>\n",
       "      <td>103.835</td>\n",
       "      <td>0.051867</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-17 18:11:00</td>\n",
       "      <td>81.544</td>\n",
       "      <td>0.205841</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17 18:12:00</td>\n",
       "      <td>103.837</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-17 18:12:00</td>\n",
       "      <td>81.548</td>\n",
       "      <td>0.205949</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-17 18:13:00</td>\n",
       "      <td>103.845</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-17 18:13:00</td>\n",
       "      <td>81.554</td>\n",
       "      <td>0.206110</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-17 18:14:00</td>\n",
       "      <td>103.833</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-17 18:14:00</td>\n",
       "      <td>81.555</td>\n",
       "      <td>0.206136</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Times  Final Price  Final Price Normalized  1h_Return  Label  \\\n",
       "0  2021-01-17 18:10:00      103.839                0.051946   0.000048      1   \n",
       "1  2021-01-17 18:11:00      103.835                0.051867  -0.000116      0   \n",
       "2  2021-01-17 18:12:00      103.837                0.051906  -0.000135      0   \n",
       "3  2021-01-17 18:13:00      103.845                0.052064   0.000010      1   \n",
       "4  2021-01-17 18:14:00      103.833                0.051827  -0.000106      0   \n",
       "\n",
       "   Currency                Times  Final Price  Final Price Normalized  \\\n",
       "0         0  2021-01-17 18:10:00       81.553                0.206083   \n",
       "1         0  2021-01-17 18:11:00       81.544                0.205841   \n",
       "2         0  2021-01-17 18:12:00       81.548                0.205949   \n",
       "3         0  2021-01-17 18:13:00       81.554                0.206110   \n",
       "4         0  2021-01-17 18:14:00       81.555                0.206136   \n",
       "\n",
       "   1h_Return  Label  Currency  \n",
       "0   0.000368      1         1  \n",
       "1   0.000270      1         1  \n",
       "2   0.000307      1         1  \n",
       "3   0.000405      1         1  \n",
       "4   0.000442      1         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all the datasets\n",
    "combined_df = pd.concat([usdjpy, cadjpy],axis=1)\n",
    "display(combined_df.head())\n",
    "\n",
    "# combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bbceed-0004-4271-b714-b3697ed08671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute technical indicator\n",
    "'''\n",
    "Calculates each technical indicator using the entire hour for each node.\n",
    "'''\n",
    "\n",
    "# Calculate Bollinger Bands for the entire hour\n",
    "def calculate_bollinger_bands(data):\n",
    "    window = len(data)\n",
    "    rolling_mean = data.rolling(window=window).mean()\n",
    "    upper_band = rolling_mean + 2 * data.rolling(window=window).std()\n",
    "    lower_band = rolling_mean - 2 * data.rolling(window=window).std()\n",
    "    \n",
    "    return upper_band.iloc[-1], lower_band.iloc[-1], rolling_mean.iloc[-1]\n",
    "\n",
    "# Calculate RSI for the entire hour\n",
    "def calculate_rsi(data):\n",
    "    diff = data.diff(1).dropna()\n",
    "    gain = diff.where(diff > 0, 0)\n",
    "    loss = -diff.where(diff < 0, 0)\n",
    "\n",
    "    avg_gain = gain.mean()\n",
    "    avg_loss = loss.mean()\n",
    "\n",
    "    if avg_loss == 0:\n",
    "        rs = np.inf  # Set to infinity to avoid division by zero\n",
    "    else:\n",
    "        rs = avg_gain / avg_loss\n",
    "\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "# Calculate RCI for the entire hour\n",
    "def calculate_rci(data):\n",
    "    rci = data.pct_change().sum()\n",
    "    return rci\n",
    "\n",
    "# Calculate Momentum for the entire hour\n",
    "def calculate_momentum(data, n=59):\n",
    "    return data.diff(n).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde9457e-1e9a-48a7-b8a8-840836ede345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create a single graph (snapshot)\n",
    "\n",
    "'''\n",
    "In each graph we use data within 18 hours.\n",
    "Each hour each currency pair forms a node, so each snapshot contains 18*9　nodes.\n",
    "Weighted edges are generated from computing DTW of two nodes (two 1 hour series) using \"Final Price Normalized\"\n",
    "Node features consist of \"Final Price Normalized\", \"1h_Return\", \"Currency\"　and technical indicator\n",
    "'''\n",
    "\n",
    "def create_graph(snapshot, node_window=60, node_stride=60):\n",
    "    \n",
    "    features = snapshot[[ 'Final Price Normalized','1h_Return', 'Currency', 'Final Price']].values\n",
    "    \n",
    "    series = []\n",
    "    currencies = []\n",
    "    prices = []\n",
    "    h_returns = []\n",
    "    Final_prices = []\n",
    "    volatilities = []\n",
    "    \n",
    "    upper_bands = []\n",
    "    lower_bands = []\n",
    "    rolling_means = []\n",
    "    rsis = []\n",
    "    rcis = []\n",
    "    momenta = []  \n",
    "    \n",
    "     \n",
    "    for i in range(0, len(snapshot) - node_window + 1, node_stride):\n",
    "        for j in range (2): \n",
    "            serie = features[i:i+node_window,j]\n",
    "            series.append(serie) \n",
    "            \n",
    "\n",
    "            currency = features[i+node_window-1,j+4]\n",
    "            currencies.append(currency)\n",
    "\n",
    "            price = features[i+node_window-1, j]\n",
    "            prices.append(price)\n",
    "            \n",
    "            Final_price = features[i:i+node_window, j+6]\n",
    "            Final_prices.append(Final_price)\n",
    "\n",
    "            h_return = features[i+node_window-1, j+2]\n",
    "            h_returns.append(h_return)\n",
    "            \n",
    "            # Create a DataFrame with the stock price data\n",
    "            df = pd.DataFrame({'Close': Final_price})\n",
    "\n",
    "            # Calculate Bollinger Bands\n",
    "            upper_band, lower_band, mean = calculate_bollinger_bands(df['Close'])\n",
    "            upper_bands.append(upper_band)\n",
    "            lower_bands.append(lower_band)\n",
    "            rolling_means.append(mean)\n",
    "\n",
    "            # Calculate RSI for the entire hour using the function\n",
    "            rsi = calculate_rsi(df['Close'])\n",
    "            rsis.append(rsi)\n",
    "\n",
    "            # Calculate RCI for the entire hour using the function\n",
    "            rci = calculate_rci(df['Close'])\n",
    "            rcis.append(rci)\n",
    "            \n",
    "            # Calculate Momentum for the entire hour using the function\n",
    "            momentum = calculate_momentum(df['Close'])\n",
    "            momenta.append(momentum)\n",
    "            \n",
    "            all_return = features[i:i+node_window, j+2]\n",
    "            \n",
    "            # Create a DataFrame with the returns\n",
    "            df_r = pd.DataFrame({'Return': all_return})\n",
    "            # Compute volatility (standard deviation of returns)\n",
    "            volatility = df_r['Return'].std()\n",
    "            volatilities.append(volatility)\n",
    "            \n",
    "    # Edge generation \n",
    "    adjacency_matrix = np.zeros((len(series), len(series)))\n",
    "    threshold = 0.85\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        for j in range(i+1, len(series)):\n",
    "            dtw_distance = dtw(series[i], series[j])\n",
    "\n",
    "            # Update the maximum observed DTW distance dynamically\n",
    "            max_dtw_distance = max(max_dtw_distance, dtw_distance) if 'max_dtw_distance' in locals() else dtw_distance\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        for j in range(i+1, len(series)):\n",
    "            dtw_distance = dtw(series[i], series[j])\n",
    "            similarity = 1 - (dtw_distance / max_dtw_distance)\n",
    "\n",
    "            \n",
    "            if similarity > threshold:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "            else:\n",
    "                adjacency_matrix[i, j] = 0\n",
    "                adjacency_matrix[j, i] = 0\n",
    "            \n",
    "    np.fill_diagonal(adjacency_matrix, 1)\n",
    "    # print(adjacency_matrix.shape)\n",
    "\n",
    "    feature_matrix = np.transpose(np.vstack((prices, h_returns, currencies, upper_bands, lower_bands, rolling_means, rsis, rcis, momenta, volatilities)))\n",
    "\n",
    "    return adjacency_matrix, feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb22bac-01f8-463e-bc26-aa33a0638aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create graphs\n",
    "'''\n",
    "Build a graph using 18 hours of data, then move forward by 1 hour and build the next graph using the next 18 hours of data,\n",
    "store them in a list graphs.\n",
    "Time window of each graph is 18*60, stride is 60.\n",
    "\n",
    "The label of each graph is the 'Lable' of the next hour's data, (\"Label\" is 1 if \"1h_return\" is larger than 1, 0 otherwise)\n",
    "Because we want to use each graph(18 hours data) to predict the next hour data.\n",
    "The label of each graph is a sequence of 9 binary values, each represents a currency.\n",
    "'''\n",
    "\n",
    "def create_graphs(data, time_window=18*60, stride=60):\n",
    "    adjacency_matrice = []\n",
    "    feature_matrice = []\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get label data\n",
    "    Label = data['Label'].values\n",
    "    \n",
    "    # Iterate through data with a sliding window\n",
    "    for i in tqdm(range(0, len(data) - 2*time_window + 1, stride)):\n",
    "    # Get a snapshot of the time series data\n",
    "        snapshot = data.iloc[i:i + time_window]\n",
    "        \n",
    "        # Generate adjacency matrix and feature matrix from the snapshot\n",
    "        adjacency_matrix, feature_matrix = create_graph(snapshot)\n",
    "        \n",
    "        # Get the label\n",
    "        label = labels_data[i + time_window + 61]\n",
    "        \n",
    "        # Create edge index indicating positions of non-zero elements\n",
    "        edge_index = torch.tensor([[i, j] for i in range(adjacency_matrix.shape[0]) for j in range(adjacency_matrix.shape[1]) if adjacency_matrix[i, j] != 0], dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        # Convert to PyTorch Tensors\n",
    "        x_tensor = torch.FloatTensor(feature_matrix)\n",
    "        y_tensor = torch.LongTensor(label)       \n",
    "\n",
    "        # Create a PyTorch Geometric Data object\n",
    "        graph = Data(x=x_tensor, edge_index=edge_index)\n",
    "        \n",
    "        # Append to the lists\n",
    "        graphs.append(graph)\n",
    "        labels.append(y_tensor)\n",
    "\n",
    "    return graphs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49b0167-6cd3-4011-be81-76299f043895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GCN\n",
    "'''\n",
    "The task is graph classification.\n",
    "Output is the label of each graph which is a sequence of 9 binary values, each represents a currency.\n",
    "'''\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Readout layer, take feature-wise average values of all node embeddings and use it as a graph feature of an input graph \n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Transform a graph feature by a linear transformation\n",
    "        x= self.linear1(x)\n",
    "        \n",
    "        #Employ a sigmoid function as an activation function of the output layer\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b5fdef-4e28-4350-b688-10613e038365",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2f16e86c744bf8a0e8cced879c51a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate all snapshots. \n",
    "graphs, labels = create_graphs(combined_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65990f1a-fe0b-4653-842d-be900b4e1da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "split_ratio = 0.85\n",
    "split_idx = int(split_ratio * len(graphs))\n",
    "\n",
    "train_data = graphs[:split_idx]\n",
    "train_labels = labels[:split_idx]\n",
    "test_data = graphs[split_idx:]\n",
    "test_labels = labels[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "830585de-3857-49ea-a308-9bbefc186044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set batch size for training\n",
    "batch_size = 64\n",
    "\n",
    "# Learning rate for optimization\n",
    "lr = 0.00125\n",
    "\n",
    "# Create DataLoader for training and test data with specified batch size and shuffle\n",
    "train_loader = DataLoader(list(zip(train_data, train_labels)), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(list(zip(test_data, test_labels)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNModel(input_dim=10, hidden_dim=32, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "157a78c5-a783-4a1e-9f27-5774f3eef76b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:50 \t loss: 0.528655\n",
      "Epoch:100 \t loss: 0.544836\n",
      "Epoch:150 \t loss: 0.537991\n"
     ]
    }
   ],
   "source": [
    "# Training loop \n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        graphs, labels = batch\n",
    "        graphs = graphs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(graphs)\n",
    "        output = output.float()\n",
    "        \n",
    "        # print(output.shape)\n",
    "        # print(labels.shape)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch:{epoch + 1} \\t loss: {loss:.6f}')\n",
    "        torch.save(model.state_dict(), 'GCN_2pairs_1h.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acd787b8-9723-4adc-b0e3-4aa231fbd95f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6341\n",
      "Precision: 0.7185\n",
      "Recall: 0.6441\n",
      "AUC: 0.7234\n",
      "AUPR: 0.7114\n",
      "F1 Score: 0.6041\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation during evaluation\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "        graphs, labels = batch\n",
    "        graphs = graphs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(graphs)\n",
    "        output = output.float()\n",
    "\n",
    "        # Convert probabilities and labels to numpy arrays for scikit-learn metrics\n",
    "        output_np = output.cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "\n",
    "        all_predictions.append(output_np)\n",
    "        all_labels.append(labels_np)\n",
    "\n",
    "# Concatenate predictions and labels across batches\n",
    "all_predictions = np.concatenate(all_predictions).flatten()\n",
    "all_labels = np.concatenate(all_labels).flatten()\n",
    "\n",
    "# Binary classification thresholding (you can adjust the threshold if needed)\n",
    "threshold = 0.5\n",
    "binary_predictions = (all_predictions > threshold).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(all_labels, binary_predictions, average='macro')\n",
    "recall = recall_score(all_labels, binary_predictions, average='macro')\n",
    "roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "aupr = average_precision_score(all_labels, all_predictions)\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'AUC: {roc_auc:.4f}')\n",
    "print(f'AUPR: {aupr:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
